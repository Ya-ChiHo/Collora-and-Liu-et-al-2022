{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to run the elastic net regression. The first and second cell were used for prototyping interactively. The third cell reflects a parameter search for an ideal alpha across datasets. The resulting alphas were aggregated and averaged to select an optimal alpha, which was then used with the fourth cell to generate the data for figures in the manuscript. The fourth cell reflects a script which will take a single alpha, run it on all datasets, and output the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import scipy as sc\n",
    "from re import sub\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#wrangling the metadata and matrix into a cohesive file\n",
    "def X_Ysplit(matrixname, targetcol):\n",
    "    X=pd.read_csv(sub(\"meta\",\"data\",matrixname), index_col=0).T\n",
    "    Y=pd.read_csv(matrixname, error_bad_lines=False, index_col=0,usecols=[targetcol], sep=\"\\t\")\n",
    "    Y=pd.to_numeric(Y[targetcol])\n",
    "    Y=np.log2((Y+min(Y))*10000)\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    return([X,Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"clonality/\")\n",
    "todo=os.listdir()\n",
    "todo=[x for x in todo if \"meta\" in x]\n",
    "todo=[x for x in todo if \"0_0\" not in x]\n",
    "#seting this up so that we're hitting the right target\n",
    "cols=[sub(\".{10,}_\",\"\", x) for x in todo]\n",
    "cols=[sub(\"Suppression|Suppressed\",\"bulkfreq_2\", x) for x in cols]\n",
    "cols=[sub(\"Viremic\",\"bulkfreq_1\", x) for x in cols]\n",
    "cols=[sub(\"Uninfected|uninfected\",\"results_freq\", x) for x in cols]\n",
    "#iterating through a large number of alphas to find out which works\n",
    "alpha = np.logspace(-3, -1, 12)\n",
    "results={}\n",
    "for file, col in zip(todo,cols):\n",
    "    print(\"starting \" + file)\n",
    "    cur_X, cur_Y = X_Ysplit(file, col)\n",
    "    clf=linear_model.ElasticNetCV(alphas=alpha, cv=5, max_iter=10000, n_jobs=-1)\n",
    "    clf.fit(cur_X, cur_Y)\n",
    "    best_score = clf.score(cur_X,cur_Y)\n",
    "    best_parameters = {'alpha': clf.alpha_}\n",
    "    \n",
    "    print(\"Best score: {:.2f}\".format(best_score))\n",
    "    print(\"Best parameters: {}\".format(best_parameters))\n",
    "    results[file]=best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to quickly write results to a file\n",
    "def writelist(towrite, file):\n",
    "    with open(file, 'w') as filehandle:\n",
    "        for listitem in towrite:\n",
    "            filehandle.write('%s\\n' % listitem)\n",
    "\n",
    "writelist([results], \"topalpha.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import scipy as sc\n",
    "from re import sub\n",
    "from sklearn import preprocessing\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"find optimal alpha and write to a file\")\n",
    "parser.add_argument('--input','-I',\n",
    "                    help='metadata file to process')\n",
    "args = parser.parse_args()\n",
    "\n",
    "def X_Ysplit(matrixname, targetcol):\n",
    "    X=pd.read_csv(sub(\"meta\",\"data\",matrixname), index_col=0).T\n",
    "    Y=pd.read_csv(matrixname, error_bad_lines=False, index_col=0,usecols=[targetcol], sep=\"\\t\")\n",
    "    Y=pd.to_numeric(Y[targetcol])\n",
    "    Y=np.log2((Y+min(Y))*10000)\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    return([X,Y])\n",
    "\n",
    "todo=[args.input]\n",
    "todo=[x for x in todo if \"meta\" in x]\n",
    "todo=[x for x in todo if \"0_0\" not in x]\n",
    "\n",
    "cols=[sub(\".{10,}_\",\"\", x) for x in todo]\n",
    "cols=[sub(\"Suppression|Suppressed\",\"bulkfreq_2\", x) for x in cols]\n",
    "cols=[sub(\"Viremic\",\"bulkfreq_1\", x) for x in cols]\n",
    "cols=[sub(\"Uninfected|uninfected\",\"results_freq\", x) for x in cols]\n",
    "\n",
    "alpha = np.logspace(-3, -1, 12)\n",
    "results={}\n",
    "\n",
    "for file, col in zip(todo,cols):\n",
    "    print(\"starting \" + file)\n",
    "    cur_X, cur_Y = X_Ysplit(file, col)\n",
    "    clf=linear_model.ElasticNetCV(alphas=alpha, cv=5, max_iter=10000, n_jobs=-1)\n",
    "    clf.fit(cur_X, cur_Y)\n",
    "    best_score = clf.score(cur_X,cur_Y)\n",
    "    best_parameters = {'alpha': clf.alpha_}\n",
    "    \n",
    "    print(\"Best score: {:.2f}\".format(best_score))\n",
    "    print(\"Best parameters: {}\".format(best_parameters))\n",
    "    results[file]=best_parameters\n",
    "\n",
    "def writelist(towrite, file):\n",
    "    with open(file, 'w') as filehandle:\n",
    "        for listitem in towrite:\n",
    "            filehandle.write('%s\\n' % listitem)\n",
    "\n",
    "writelist([results], todo[0]+\"alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onealpha.py, set the alpha at the top and its just works \n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import scipy as sc\n",
    "from re import sub\n",
    "from sklearn import preprocessing\n",
    "import argparse\n",
    "#parse args \n",
    "parser = argparse.ArgumentParser(description=\"find optimal alpha and write to a file\")\n",
    "parser.add_argument('--input','-I',\n",
    "                    help='metadata file to process')\n",
    "args = parser.parse_args()\n",
    "#determined in the previous step\n",
    "alpha = [0.0285]\n",
    "#utility functions to load and save data \n",
    "def X_Ysplit(matrixname, targetcol):\n",
    "    X=pd.read_csv(sub(\"meta\",\"data\",matrixname), index_col=0).T\n",
    "    Y=pd.read_csv(matrixname, error_bad_lines=False, index_col=0,usecols=[targetcol], sep=\"\\t\")\n",
    "    Y=pd.to_numeric(Y[targetcol])\n",
    "    Y=np.log2((Y+min(Y))*10000)\n",
    "    return([X,Y, list(X)])\n",
    "#used to write gene weights \n",
    "def writecoef(model, genes,file):\n",
    "    with open(file, 'w') as filehandle:\n",
    "        for gene, co in zip(genes,list(model.coef_)):\n",
    "            filehandle.write('%s\\t%s\\n' % (gene, str(co)))\n",
    "\n",
    "#change names so that everything is teed up \n",
    "\n",
    "todo=[args.input]\n",
    "todo=[x for x in todo if \"meta\" in x]\n",
    "todo=[x for x in todo if \"0_0\" not in x]\n",
    "\n",
    "cols=[sub(\".{10,}_\",\"\", x) for x in todo]\n",
    "cols=[sub(\"unstimulated_meta_Viremic|unstimulated_meta_Suppressed\",\"results_freq\", x) for x in cols]\n",
    "cols=[sub(\"Suppression|Suppressed\",\"bulkfreq_2\", x) for x in cols]\n",
    "cols=[sub(\"Viremic\",\"bulkfreq_1\", x) for x in cols]\n",
    "cols=[sub(\"Uninfected|uninfected\",\"results_freq\", x) for x in cols]\n",
    "\n",
    "#load data in and fit model\n",
    "for file, col in zip(todo,cols):\n",
    "    print(\"starting \" + file)\n",
    "    cur_X, cur_Y, X = X_Ysplit(file, col)\n",
    "    cur_X = preprocessing.StandardScaler().fit_transform(cur_X)\n",
    "    clf=linear_model.ElasticNetCV(alphas=alpha, cv=5, max_iter=10000, n_jobs=-1)\n",
    "    clf.fit(cur_X, cur_Y)\n",
    "    \n",
    "writecoef(clf, list(X), todo[0]+\"results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
